{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div\n",
    "    style='background-image: url(\"images/earthquake.jpg\"); padding: 0px;\n",
    "    background-size: cover; border-radius: 10px; height: 350px;\n",
    "    background-position: 50% 50%'>\n",
    "    <div\n",
    "        style=\"position: relative; top: 75%; margin: 20px; padding: 10px;\n",
    "        background: rgba(255 , 255 , 255 , 0.8); width: 95%; height: 80px;\n",
    "        border-radius: 10px\">\n",
    "        <div\n",
    "            style=\"position: relative; top: 50%;\n",
    "            transform: translatey(-50%)\">\n",
    "            <div\n",
    "                style=\"font-size: large; font-weight: 900;\n",
    "                color: rgba(0 , 0 , 0 , 0.9);\n",
    "                line-height: 100%\">\n",
    "                Introduction to seismo-acoustic waves in the Earth’s spheres\n",
    "            </div>\n",
    "            <div\n",
    "                style=\"font-size: large; padding-top: 20px;\n",
    "                color: rgba(0 , 0 , 0 , 0.7)\">\n",
    "                <p>Interpreting transient signals by <em>Shahar Shani-Kadmiel</em>, CEG, TU Delft\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting transient signals\n",
    "---\n",
    "## Introduction\n",
    "In this session we will discuss how array processing techniques can aid in the interpretation of transient signals. We will first go through the process of selecting an event and finding arrays that might have recorded it. We will then download array metadata and raw waveforms and try to get a feeling for what kind of signals we are able to see in the waveforms at different frequency bands.\n",
    "\n",
    "Next we will use our array processing knowledge from the previous session to retrieve the wavefront parameters which will facilitate further analysis of the event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving data\n",
    "There are several ways to retrieve data from various data services. We will look at the manual way, which uses a GUI-like interface in a web browser and the automatic way, which uses python code to directly interface with the online data services.\n",
    "\n",
    "### IRIS GUI\n",
    "\n",
    "[Wilber 3](https://ds.iris.edu/wilber3/find_event) is an Incorporated Research Institutions for Seismology (IRIS) data service that lets you select an earthquake and then select stations that have recorded that earthquake. It is possible to plot the waveforms prior to downloading the data.\n",
    "\n",
    "Head over to the [Wilber 3](https://ds.iris.edu/wilber3/find_event) page and select the October 30, 2016 <i>M</i><sub>w</sub> 6.6 earthquake in Central Italy.\n",
    "\n",
    "![IRIS__Wilber_3__Select_Event.png](images/IRIS__Wilber_3__Select_Event.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, look for all stations that have a `??F` (infrasound) channel. You should see I26H[1-8] (amongst others), which is an infrasound array of the IMS situated in Germany.\n",
    "\n",
    "![IRIS__Wilber_3__Select_Stations.png](images/IRIS__Wilber_3__Select_Stations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Go ahead and request some data... after you have downloaded the data, use ``obspy`` to read and plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from obspy import read\n",
    "\n",
    "# wite some code here\n",
    "raw_stream = read('path_to_your_data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noted that using this interface, you are limited in terms of the amount of data you can request.\n",
    "\n",
    "Let's look at what python can do for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ObsPy FDSN client\n",
    "\n",
    "ObsPy is an open-source project dedicated to provide a Python framework for processing seismological data. It provides parsers for common file formats, clients to access data centers and seismological signal processing routines which allow the manipulation of seismological time series.\n",
    "\n",
    "We will look at the [FDSN client](https://docs.obspy.org/packages/obspy.clients.fdsn.html) of ObsPy for retrieving station metadata and waveform data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching [event metadata](https://docs.obspy.org/packages/autogen/obspy.clients.fdsn.client.Client.get_events.html#obspy-clients-fdsn-client-client-get-events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "client = Client('IRIS')\n",
    "\n",
    "origintime = UTCDateTime('2016-10-30T06:40:19')\n",
    "\n",
    "events = client.get_events(origintime - 5, origintime + 5, minmagnitude=6)\n",
    "print(events)\n",
    "\n",
    "event = events[0]\n",
    "source_lon = event.origins[0].longitude\n",
    "source_lat = event.origins[0].latitude\n",
    "source_depth = event.origins[0].depth * 1e-3\n",
    "source_mag = event.magnitudes[0].mag\n",
    "origintime = event.origins[0].time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching [station metadata](https://docs.obspy.org/packages/autogen/obspy.clients.fdsn.client.Client.get_stations.html#obspy-clients-fdsn-client-client-get-stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import UTCDateTime\n",
    "from obspy.clients.fdsn import Client\n",
    "client = Client('BGR')\n",
    "\n",
    "origintime = UTCDateTime('2016-10-30T06:40:19')\n",
    "\n",
    "inv = client.get_stations(\n",
    "    origintime, network='*', station='I26*', channel='??F', level='response')\n",
    "print(inv)\n",
    "\n",
    "inv.write('../../Data/IS26.xml', 'StationXML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already have a look at the instrument response. Try changing to different stations (array elements) to see if the instrument response is the same."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from obspy import read_inventory\n",
    "origintime = UTCDateTime('2016-10-30T06:40:19')\n",
    "inv = read_inventory('../../Data/IS26.xml')\n",
    "print(inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching [waveforms](https://docs.obspy.org/packages/autogen/obspy.clients.fdsn.client.Client.get_waveforms.html#obspy-clients-fdsn-client-client-get-waveforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = origintime - 5 * 60\n",
    "t1 = origintime + 3500\n",
    "raw_stream = client.get_waveforms(\n",
    "    network='GR', station='I26*', location='*', channel='BDF',\n",
    "    starttime=t0, endtime=t1).sort()\n",
    "print(raw_stream)\n",
    "raw_stream.plot(size=(600, 600))\n",
    "\n",
    "raw_stream.write(\n",
    "    '../../Data/{}.mseed'.format(origintime.strftime('%Y%m%d%H%M%S')),\n",
    "    format='MSEED'\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from obspy import read\n",
    "\n",
    "t0 = origintime - 5 * 60\n",
    "t1 = origintime + 3500\n",
    "\n",
    "raw_stream = read(\n",
    "    '../../Data/{}.mseed'.format(origintime.strftime('%Y%m%d%H%M%S')),\n",
    "    format='MSEED'\n",
    ")\n",
    "print(raw_stream)\n",
    "raw_stream.plot(size=(600, 600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seismic phase picking\n",
    "\n",
    "ObsPy can also be used to calculate theoretical arrival times for arbitrary seismic phases in a 1D spherically symmetric background model. Furthermore it can output ray paths for all phases and derive pierce points of rays with model discontinuities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from obspy.taup import TauPyModel, plot_travel_times\n",
    "model = TauPyModel(model='ak135')\n",
    "\n",
    "phases = model.get_ray_paths(source_depth_in_km=source_depth,\n",
    "                             distance_in_degree=6,\n",
    "                             phase_list=['P', 'S', 'PcP', 'ScS', 'PKiKP'])\n",
    "print(phases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the Array object\n",
    "The Array class inherits the functionality and hierarchy of the [ObsPy Inventory class](https://docs.obspy.org/packages/autogen/obspy.core.inventory.inventory.Inventory.html#obspy-core-inventory-inventory-inventory). The Array class provides some additional attributes and methods:\n",
    "\n",
    "Attributes:\n",
    "\n",
    "- ``name`` : The name of the array.\n",
    "- ``aperture`` : The largest inter-station distance.\n",
    "- ``center`` : Longitude, latitude, and elevation of the center of the array\n",
    "- ``elements`` : A list of elements which are part of the array.\n",
    "- ``nelements`` : Number of array elements.\n",
    "\n",
    "Methods:\n",
    "\n",
    "- ``get_coordinates()`` : Coordinates of array elements.\n",
    "- ``plot_array_geometry()`` : Plot array configuration/geometry in Cartesian coordinates.\n",
    "- ``plot_array_response()`` : Calculate and plot the array transfer response functions.\n",
    "\n",
    "An Array instance can be initiated with an Inventory object already in memory or from a StationXML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arraylib import Array\n",
    "array = Array(inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instrument response of the sensors of this specific array is mostly flat between 0.1 and 5 Hz which is more or less the frequency band we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = array.plot_response(0.01, station='I26H1', show=False)\n",
    "ax1, ax2 = fig.axes\n",
    "ax1.set_ylim(3e3, 8e3)\n",
    "ax1.axvspan(0.1, 5, color='r', alpha=0.1)\n",
    "ax2.axvspan(0.1, 5, color='r', alpha=0.1)\n",
    "plt.tight_layout()\n",
    "\n",
    "print(inv.get_response('GR.I26H1..BDF', origintime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the array response plot, change the frequencies to try and figure out what is the frequency range the array is designed to be sensitive for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the plot\n",
    "fwidth = 7\n",
    "fheight = 4.5\n",
    "fig = plt.figure(figsize=(fwidth, fheight))\n",
    "wspace = 0.12\n",
    "hspace = 0.05\n",
    "left = 0.1\n",
    "right = 0.15\n",
    "bottom = 0.15\n",
    "ncols = 2\n",
    "width = (1 - left - right - wspace) / ncols\n",
    "aspect = fwidth / fheight\n",
    "height = width * aspect\n",
    "ax1 = fig.add_axes((left, bottom,\n",
    "                    width, height))\n",
    "ax2 = fig.add_axes((left + width + wspace, bottom,\n",
    "                    width, height))\n",
    "ax02 = fig.add_axes((left + width + wspace, bottom + height + hspace,\n",
    "                     width, 0.2), sharex=ax2)\n",
    "plt.setp(ax02.get_xticklabels(), visible=False)\n",
    "\n",
    "# array configuration\n",
    "array.plot_array_geometry(ax1, c='r')\n",
    "\n",
    "# array response\n",
    "cbx = fig.add_axes((left + 2 * width + wspace + 0.015, bottom,\n",
    "                    0.015, height))\n",
    "\n",
    "\n",
    "\n",
    "# change frequencies here:\n",
    "resp = array.plot_array_response(f_min=0.3, f_max=3, f_steps=1,\n",
    "                                 ax=ax2, ax_top=ax02, cb_ax=cbx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the raw waveforms did not look like much. Use the [filter](https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.filter.html#obspy-core-trace-trace-filter) method to filter out the low frequency oscillations and the high frequency noise. Bare in mind the instrument and array response that we have just discussed. Also, use the [remove_respose](https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.remove_response.html#obspy-core-trace-trace-remove-response) method to deconvolve with the instrument response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = raw_stream.copy()\n",
    "stream.detrend('demean')\n",
    "stream.taper(type='cosine', max_percentage=0.05)\n",
    "\n",
    "# filter the data here:\n",
    "stream.filter()\n",
    "\n",
    "\n",
    "stream.remove_response(inv)\n",
    "stream.plot(size=(600, 600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get better control over plotting we will define our own plotting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHASE_COLORS = {'P': 'b',\n",
    "                'S': 'r',\n",
    "                'PcP': 'g',\n",
    "                'ScS': 'orange'}\n",
    "\n",
    "def plot_waveforms(stream, origintime=None, phases=None):\n",
    "    fig, ax = plt.subplots(stream.count(), 1, sharex=True, sharey=True,\n",
    "                           figsize=(7, 1 * stream.count()))\n",
    "    \n",
    "    origintime = origintime or 0\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    for i, tr in enumerate(stream):\n",
    "        times = tr.times()\n",
    "        \n",
    "        pre_origintime = origintime - tr.stats.starttime\n",
    "        times -= pre_origintime\n",
    "        \n",
    "        axi = ax[i]\n",
    "        axi.plot(times, tr.data, 'k', lw=0.5)\n",
    "        axi.text(0.99, 0.97, tr.id, ha='right', va='top',\n",
    "                 transform=axi.transAxes)\n",
    "        \n",
    "        # plot phases\n",
    "        try:\n",
    "            plotted = []\n",
    "            for phase in phases:\n",
    "                if phase.name in plotted:\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    color = PHASE_COLORS[phase.name]\n",
    "                except KeyError:\n",
    "                    color = 'k'\n",
    "                axi.vlines(phase.time, tr.data.min(), tr.data.max(),\n",
    "                           colors=color, label=phase.name)\n",
    "                plotted.append(phase.name)\n",
    "        except TypeError:\n",
    "            pass\n",
    "        \n",
    "    axi.set_xlim(times[0], times[-1])\n",
    "    if phases:\n",
    "        axi.legend(loc=9, bbox_to_anchor=(0.5, -0.45), ncol=5, frameon=False)\n",
    "    \n",
    "    try:\n",
    "        axi.set_xlabel('Time since origin {}'.format(\n",
    "            origintime.strftime('%FT%T')\n",
    "        ))\n",
    "    except AttributeError:\n",
    "        axi.set_xlabel('Time since {}'.format(\n",
    "            tr.stats.starttime.strftime('%FT%T')\n",
    "        ))\n",
    "        \n",
    "    try:\n",
    "        for step in tr.stats.processing:\n",
    "            if 'remove_response' in step or 'remove_sensitivity' in step:\n",
    "                axi.set_ylabel('Pressure, Pa')\n",
    "            else:\n",
    "                axi.set_ylabel('Counts')\n",
    "    except AttributeError:\n",
    "        axi.set_ylabel('Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_waveforms(stream, origintime, phases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beamforming\n",
    "We can now start the beamforming process to retrieve the wavefront parameters for the various signals in our data.\n",
    "\n",
    "### Grid design\n",
    "\n",
    "Yesterday we used a square slowness grid that was evenly spaced in slowness space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from grid import Grid\n",
    "grid = Grid(app_vel_params=(200, 50))\n",
    "grid.plot_pxpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are many points in the corners outside the minimum velocity we are interested in. This obviously adds a computational overhead in the grid search process during beamforming. We also have no control over the resolution in velocity space which is unfavorable. For many reasons it makes more sense to do the grid search over a polar slowness grid with a known resolution in apparent velocity and back-azimuth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = Grid(app_vel_params=(280, 450, 10), theta_params=(0, 360, 2))\n",
    "grid.plot_pxpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This grid will resolve wavefront parameters in the acoustic range and will treat signals outside this range as noise. In this case, we are interested in retrieving wavefront parameters over a large range of apparent velocities so it also makes sense to have an evenly spaced grid for the acoustic range and a lower resolution log-spaced grid for the seismic range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid = Grid(app_vel_params=(280, 6000, 10, 450, 3), theta_params=(0, 360, 2))\n",
    "grid.plot_pxpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "\n",
    "We have already detrended, tapered, filtered, and deconvolved the instrument response. We need to make sure that all traces begin and end in the same time and have the same number of samples, and add the x, y attributes to each trace, the coordinates of the corresponding array element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = raw_stream.copy()\n",
    "stream.detrend('demean')\n",
    "stream.taper(type='cosine', max_percentage=0.05)\n",
    "\n",
    "# filter the data here\n",
    "stream.filter()\n",
    "\n",
    "\n",
    "stream.remove_response(inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim to the same start and end time\n",
    "stream.trim(t0, t1, pad=True, fill_value=0)\n",
    "\n",
    "# assign the x, y attributes and validate smapling rate and number of samples\n",
    "samp_rate = []\n",
    "npts = []\n",
    "for tr in stream:\n",
    "    element = array.select(station=tr.stats.station)[0][0]\n",
    "    tr.x, tr.y = element.x, element.y\n",
    "    samp_rate.append(tr.stats.sampling_rate)\n",
    "    npts.append(tr.stats.npts)\n",
    "    \n",
    "if np.any(np.array(samp_rate) - tr.stats.sampling_rate):\n",
    "    raise RuntimeError(\"Sampling rate does not match. {}\".format(samp_rate))\n",
    "if np.any(np.array(npts) - tr.stats.npts):\n",
    "    raise RuntimeError(\"Number of samples does not match. {}\".format(npts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from timefisher import beamform, fratio2snr, plot_results\n",
    "\n",
    "bestbeam, times, fratio_max, baz, app_vel, fgrid = beamform(\n",
    "    stream, grid, wlen=30, version='python')\n",
    "\n",
    "snr = fratio2snr(fratio_max, stream.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "\n",
    "array_lon, array_lat, array_elev = array.center\n",
    "\n",
    "distance, true_az, true_baz = gps2dist_azimuth(\n",
    "    source_lat, source_lon, array_lat, array_lon\n",
    ")\n",
    "distance *= 1e-3\n",
    "\n",
    "fig, ax, cb1, cb2 = plot_results(\n",
    "    bestbeam, times, fratio_max, baz, app_vel, snr,\n",
    "    stream, origintime, distance\n",
    ")\n",
    "\n",
    "# set the y-limits of the spectrogram frame\n",
    "ax[0].set_ylim(0.3, 5)\n",
    "ax[3].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "def plot_fgrid(times, bin, fgrid, origintime=None, cmap='inferno_r', ax=None,\n",
    "               title=None):\n",
    "    dt = times[1] - times[0]\n",
    "    \n",
    "    try:\n",
    "        plt.sca(ax)\n",
    "    except ValueError:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    im = ax.tripcolor(grid.px, grid.py, fgrid[bin],\n",
    "                 cmap=cmap, shading='gouraud')\n",
    "    \n",
    "    ax.set_aspect(1)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cbx = divider.append_axes('right', 0.15, 0.15)\n",
    "    plt.colorbar(im, cax=cbx, label='Fisher ratio')\n",
    "    \n",
    "    ax.set_xlabel('px, s/m')\n",
    "    ax.set_ylabel('py, s/m')\n",
    "    if title is None:\n",
    "        ax.set_title(\n",
    "            ('Fisher ratio grid for time bin centered at:\\n'\n",
    "             f'{times[bin]:.2f} seconds')\n",
    "        )\n",
    "    \n",
    "t_offset = bestbeam.stats.starttime - origintime\n",
    "detection_times = times + t_offset\n",
    "    \n",
    "def update_plot(bin):\n",
    "    plot_fgrid(detection_times, bin, fgrid)\n",
    "\n",
    "\n",
    "    \n",
    "from ipywidgets import interact, fixed, IntSlider\n",
    "interact(\n",
    "    update_plot,\n",
    "    bin=IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=times.size,\n",
    "        step=5,\n",
    "        continuous_update=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript  # to have equation numbering\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprojections\n",
    "\n",
    "Let's assume that each detection in the above array processing results is a signal that has propagated part of the way in the solid earth and the rest of the way in the atmosphere. As each detection point has a travel-time and a back-azimuth associated with it, we can map it to a geographical location relative to the array.\n",
    "\n",
    "![Seismo-acoustic coupling cartoon](images/coupling_cartoon.png)\n",
    "\n",
    "This is done by minimizing the misfit both in time and in back-azimuth in a grid search algorithm:\n",
    "\n",
    "A travel-time matrix, $T_{ij}$, and a back-azimuth matrix, $BAZ_{ij}$, are constructed over the geographical extent of interest at $dh$ degrees grid spacing. Every grid point $(i, j)$ is treated as a potential point at which seismic waves may couple to infrasound. $T_{ij}$ is therefore the sum of the seismic travel-time, $T_{S,{ij}}$, from the hypocenter to each grid point:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "T_{S,{ij}} = (h^2 + Rs_{ij}^2)^{0.5}/c_s ,\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "and $T_{I,{ij}}$, the infrasonic travel-time from that grid point to the array:\n",
    "\n",
    "\\begin{equation}\n",
    "T_{I,{ij}} = R_{I,{ij}}/c_I ,\n",
    "\\end{equation}\n",
    "\n",
    "where $h$ is the hypocentral depth of the event, $R_{S,{ij}}$ and $R_{I,{ij}}$ are distance along a great circle of the seismic and infrasonic paths, respectively and $c_s$ and $c_I$ are seismic and infrasonic propagation velocities. Back-azimuth to each point is:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:3}\n",
    "BAZ_{ij} = \\arctan \\left( \\frac{(\\sin(\\phi_{ij} - \\phi_a)}\n",
    "    {\\cos(\\lambda_a) \\tan(\\lambda_{ij}) -\n",
    "     \\sin(\\lambda_a) \\cos(\\phi_{ij} - \\phi_a)} \\right) ,\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "$\\lambda_{ij}$, $\\phi_{ij}$ are the latitude and longitude of a given point $(i, j)$, and $\\lambda_a$, $\\phi_a$ are the central coordinates of the array.\n",
    "\n",
    "For each back-azimuth detection point, $BAZ_d$ at time $T_d$, we evaluate the joint misfit $M$ to be\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "M = M_{BAZ,{ij}} \\cdot M_{T,{ij}},\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "where $M_{BAZ,{ij}} = | BAZ_{ij} - BAZ_d |$ and $M_{T,{ij}} = | T_{ij} - T_d |$ are the back-azimuth and travel-time residual matrices, respectively. The grid point ($i, j$) which corresponds to $\\min(M)$ is then most likely the point at which an infrasound detection with back-azimuth, $BAZ_d$ at time $T_d$, originated from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backproject import backproject\n",
    "backproject??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `times` aligned with the bestbeem which starts before origintime\n",
    "# don't forget to subtract the pre-origintime\n",
    "\n",
    "pre_origintime = origintime - bestbeam.stats.starttime\n",
    "times_corrected = times - pre_origintime\n",
    "\n",
    "# filter detections\n",
    "detections = (\n",
    "    (snr > 0.5) * \n",
    "    (times_corrected > 0) * \n",
    "    \n",
    "    # similarly, filter out the detections from the north-west\n",
    ")\n",
    "\n",
    "T_d = times_corrected[detections]\n",
    "BAZ_d = baz[detections]\n",
    "\n",
    "# set the grid search extent (w, e, s, n)\n",
    "grid_extent = (7, 18, 40, 50)\n",
    "\n",
    "lons, lats = backproject(\n",
    "    (source_lon, source_lat, source_depth), array.center,\n",
    "    T_d, BAZ_d, extent=grid_extent, c_i=0.27\n",
    ")\n",
    "\n",
    "color_code = snr[detections]\n",
    "sort_idx = color_code.argsort()\n",
    "plt.close('all')\n",
    "plt.scatter(lons[sort_idx], lats[sort_idx], 10, c=color_code[sort_idx],\n",
    "            cmap='inferno_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "def read_GeoTIFF(filename):\n",
    "    \"\"\"\n",
    "    Get data from GeoTIFF file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path (relative or absolute) to a GeoTIFF file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    z : :class:`~numpy.ndarray`\n",
    "        Array (2d) of raster band data.\n",
    "        \n",
    "    (w, e, s, n) : tuple\n",
    "        Extent of the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    src_ds = gdal.Open(filename)\n",
    "    band = src_ds.GetRasterBand(1)\n",
    "    \n",
    "    # elevation data\n",
    "    z = band.ReadAsArray()\n",
    "    \n",
    "    # geo extent\n",
    "    geotransform = src_ds.GetGeoTransform()\n",
    "    w = geotransform[0]\n",
    "    n = geotransform[3]\n",
    "    dx = geotransform[1]\n",
    "    dy = geotransform[5]\n",
    "    \n",
    "    nx = z.shape[1]\n",
    "    ny = z.shape[0]\n",
    "    e = w + nx * dx\n",
    "    s = n + ny * dy\n",
    "        \n",
    "    return z, (w, e, s, n)\n",
    "\n",
    "\n",
    "import shapefile\n",
    "def read_shapefile(filename):\n",
    "    \"\"\"\n",
    "    Get shapes from ESRI shapefile.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path (relative or absolute) to a .shp file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    shapes : list\n",
    "        List of all shapes in shapefile.\n",
    "    \"\"\"\n",
    "    \n",
    "    sf = shapefile.Reader(filename)\n",
    "    return sf.shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read shaded relief data\n",
    "z, extent = read_GeoTIFF('../../Data/GEBCO_2014.hillshade.tiff')\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "# plot relief\n",
    "im = ax.imshow(z, 'Greys_r', extent=extent, aspect='auto',\n",
    "               interpolation='bilinear', vmin=50, vmax=220)\n",
    "\n",
    "# read coastline data\n",
    "shapes = read_shapefile('../../Data/ne_10m_coastline/ne_10m_coastline.shp')\n",
    "\n",
    "# plot coastlines\n",
    "for shape in shapes:\n",
    "    x, y = np.array(shape.points).T\n",
    "    ax.plot(x, y, 'k', lw=0.5, zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patheffects import withStroke\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.axis(grid_extent)\n",
    "\n",
    "# plot relief\n",
    "im = ax.imshow(z, 'Greys_r', extent=extent, aspect='auto',\n",
    "               interpolation='bilinear', vmin=0, vmax=200, zorder=0)\n",
    "\n",
    "# plot coastlines\n",
    "for shape in shapes:\n",
    "    x, y = np.array(shape.points).T\n",
    "    ax.plot(x, y, 'k', lw=0.5,\n",
    "            path_effects=[withStroke(linewidth=3, foreground=\"w\")], zorder=2)\n",
    "\n",
    "# plot source and receiver\n",
    "ax.scatter(source_lon, source_lat, s=150, c='none', marker='*', edgecolor='k',\n",
    "           path_effects=[withStroke(linewidth=3, foreground=\"w\")], zorder=10)\n",
    "ax.scatter(array_lon, array_lat, s=100, c='none', marker='^', edgecolor='k',\n",
    "           path_effects=[withStroke(linewidth=3, foreground=\"w\")], zorder=10)\n",
    "\n",
    "# plot locations of seismo-acoustic coupling\n",
    "sp = ax.scatter(lons[sort_idx], lats[sort_idx], 20,\n",
    "                c=color_code[sort_idx], vmax=0.85 * color_code.max(),\n",
    "                cmap='inferno_r', zorder=5)\n",
    "plt.colorbar(sp, extend='both', label='SNR of detection', aspect=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More refined backprojections\n",
    "\n",
    "As we are interested in detections in the 90° -> 270° back azimuth range, we can limit our beamforming to that range instead of filtering the results in the post-processing stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "grid = Grid(app_vel_params=(280, 6000, 5, 450, 3), theta_params=(90, 270, 1))\n",
    "grid.plot_pxpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also want to tweak the bandpass filter parameters we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = raw_stream.copy()\n",
    "stream.detrend('demean')\n",
    "stream.taper(type='cosine', max_percentage=0.05)\n",
    "stream.filter('bandpass', freqmin=0.4, freqmax=3, corners=4, zerophase=True)\n",
    "stream.remove_response(inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim to the same start and end time\n",
    "stream.trim(t0, t1, pad=True, fill_value=0)\n",
    "\n",
    "# assign the x, y attributes and validate smapling rate and number of samples\n",
    "samp_rate = []\n",
    "npts = []\n",
    "for tr in stream:\n",
    "    element = array.select(station=tr.stats.station)[0][0]\n",
    "    tr.x, tr.y = element.x, element.y\n",
    "    samp_rate.append(tr.stats.sampling_rate)\n",
    "    npts.append(tr.stats.npts)\n",
    "    \n",
    "if np.any(np.array(samp_rate) - tr.stats.sampling_rate):\n",
    "    raise RuntimeError(\"Sampling rate does not match. {}\".format(samp_rate))\n",
    "if np.any(np.array(npts) - tr.stats.npts):\n",
    "    raise RuntimeError(\"Number of samples does not match. {}\".format(npts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point on we will use a more optimized version of our beamforming algorithm that uses multi-threading as well to speed up processing. Add the ``version=numba`` keyword argument to the ``beamform()`` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timefisher import beamform, fratio2snr, plot_results\n",
    "\n",
    "bestbeam, times, fratio_max, baz, app_vel, fgrid = beamform(\n",
    "    stream, grid, wlen=15, overlap=0.9, version='numba')\n",
    "\n",
    "snr = fratio2snr(fratio_max, stream.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from obspy.geodetics import gps2dist_azimuth\n",
    "\n",
    "array_lon, array_lat, array_elev = array.center\n",
    "\n",
    "distance, true_az, true_baz = gps2dist_azimuth(\n",
    "    source_lat, source_lon, array_lat, array_lon\n",
    ")\n",
    "distance *= 1e-3\n",
    "\n",
    "fig, ax, cb1, cb2 = plot_results(\n",
    "    bestbeam, times, fratio_max, baz, app_vel, snr,\n",
    "    stream, origintime, distance,\n",
    "    vmin=0.5\n",
    ")\n",
    "\n",
    "ax[0].set_ylim(0.4, 5)\n",
    "ax[2].set_ylim(90, 270)\n",
    "ax[3].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.gradient(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "def plot_fgrid(times, bin, fgrid, origintime=None, cmap='inferno_r', ax=None,\n",
    "               title=None):\n",
    "    dt = times[1] - times[0]\n",
    "    \n",
    "    try:\n",
    "        plt.sca(ax)\n",
    "    except ValueError:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    im = ax.tripcolor(grid.px, grid.py, fgrid[bin],\n",
    "                 cmap=cmap, shading='gouraud')\n",
    "    \n",
    "    ax.set_aspect(1)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cbx = divider.append_axes('right', 0.15, 0.15)\n",
    "    plt.colorbar(im, cax=cbx, label='Fisher ratio')\n",
    "    \n",
    "    ax.set_xlabel('px, s/m')\n",
    "    ax.set_ylabel('py, s/m')\n",
    "    if title is None:\n",
    "        ax.set_title(\n",
    "            ('Fisher ratio grid for time bin centered at:\\n'\n",
    "             f'{times[bin]:.2f} seconds')\n",
    "        )\n",
    "    \n",
    "t_offset = bestbeam.stats.starttime - origintime\n",
    "detection_times = times + t_offset\n",
    "    \n",
    "def update_plot(bin):\n",
    "    plot_fgrid(detection_times, bin, fgrid)\n",
    "\n",
    "\n",
    "    \n",
    "from ipywidgets import interact, fixed, IntSlider\n",
    "interact(\n",
    "    update_plot,\n",
    "    bin=IntSlider(\n",
    "        value=250,\n",
    "        min=0,\n",
    "        max=times.size,\n",
    "        step=5,\n",
    "        continuous_update=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `times` aligned with the bestbeem which starts before origintime\n",
    "# don't forget to subtract the pre-origintime\n",
    "\n",
    "pre_origintime = origintime - bestbeam.stats.starttime\n",
    "times_corrected = times - pre_origintime\n",
    "\n",
    "# filter detections\n",
    "detections = (\n",
    "    (snr > 0.5) * \n",
    "    (times_corrected > 0)\n",
    ")\n",
    "\n",
    "T_d = times_corrected[detections]\n",
    "BAZ_d = baz[detections]\n",
    "\n",
    "# set the grid search extent (w, e, s, n)\n",
    "grid_extent = (7, 18, 40, 50)\n",
    "\n",
    "lons, lats = backproject(\n",
    "    (source_lon, source_lat, source_depth), array.center,\n",
    "    T_d, BAZ_d, extent=grid_extent, c_i=0.27\n",
    ")\n",
    "\n",
    "color_code = snr[detections]\n",
    "sort_idx = color_code.argsort()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 5))\n",
    "ax.axis(grid_extent)\n",
    "\n",
    "# plot relief\n",
    "im = ax.imshow(z, 'Greys_r', extent=extent, aspect='auto',\n",
    "               interpolation='bilinear', vmin=0, vmax=200, zorder=0)\n",
    "\n",
    "# plot coastlines\n",
    "for shape in shapes:\n",
    "    x, y = np.array(shape.points).T\n",
    "    ax.plot(x, y, 'k', lw=0.5,\n",
    "            path_effects=[withStroke(linewidth=3, foreground=\"w\")], zorder=2)\n",
    "\n",
    "# plot source and receiver\n",
    "ax.scatter(source_lon, source_lat, s=150, c='none', marker='*', edgecolor='k',\n",
    "           path_effects=[withStroke(linewidth=3, foreground=\"w\")], zorder=10)\n",
    "ax.scatter(array_lon, array_lat, s=100, c='none', marker='^', edgecolor='k',\n",
    "           path_effects=[withStroke(linewidth=3, foreground=\"w\")], zorder=10)\n",
    "\n",
    "# make a histogram of the data \n",
    "w, e, s, n = grid_extent\n",
    "H, Xe, Ye = np.histogram2d(lons, lats, bins=20, range=((w, e), (s, n)))\n",
    "H = H.T\n",
    "\n",
    "# plot histogram\n",
    "cmap = plt.get_cmap('bone_r')\n",
    "cmap.set_under('w')\n",
    "cmap.set_over('k')\n",
    "heatmap = ax.imshow(H, cmap, interpolation='gaussian', origin='lower',\n",
    "                    aspect='auto', alpha=0.7, vmin=1, vmax=30,\n",
    "                    extent=[Xe[0], Xe[-1], Ye[0], Ye[-1]], zorder=1)\n",
    "cb = plt.colorbar(heatmap, extend='both', label='Number of detections',\n",
    "                  aspect=30)\n",
    "cb.solids.set_edgecolor(\"face\")\n",
    "\n",
    "# plot locations of seismo-acoustic coupling\n",
    "sp = ax.scatter(lons[sort_idx], lats[sort_idx], 3,\n",
    "                c=color_code[sort_idx], vmax=0.85 * color_code.max(),\n",
    "                cmap='inferno_r', zorder=5)\n",
    "plt.colorbar(sp, extend='both', label='SNR of detection', aspect=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach does not account for atmospheric effects such as velocity of the wind components and temperature variations that affect sound speeds and may result in inaccurate locations. The longer the propagation range, the more this approach is prone to error. The manifestation of such errors is visible as the epicentral infrasound detections are offset to the east relative to the epicenter. This is due to stratospheric cross-winds along the propagation path which leads to a discrepancy in back-azimuth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "\n",
    "Now that you have a workflow for array processing and backprojection of transient seismo-acoustic signals, pick an earthquake from the list below and provide an analysis of the event.\n",
    "\n",
    "Earthquakes:\n",
    "\n",
    "1. Mw 9.1 2011-03-11 05:46:23\n",
    "1. Mw 7.8 2012-10-28 03:04:07\n",
    "1. Mw 7.5 2013-01-05 08:58:19\n",
    "1. Mw 6.0 2016-08-24 01:36:32\n",
    "1. Mw 5.9 2016-10-26 19:18:05\n",
    "1. Mw 6.3 2017-09-03 03:30:01\n",
    "1. Mw 7.9 2018-01-23 09:31:42\n",
    "1. Mw 6.3 2018-08-12 14:58:54\n",
    "1. Mw 7.0 2018-11-30 17:29:29\n",
    "\n",
    "Consult us if you don't find data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
